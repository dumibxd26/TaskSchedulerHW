{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32737a65-a874-4ae8-9702-cd66987161d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "JSON_PATH = \"rr_results_full_json.json\"  # <-- change to your file name/path\n",
    "\n",
    "def load_json_lenient(path: str):\n",
    "    \"\"\"\n",
    "    Loads a JSON list of objects. If the file has the common '}{' missing comma issue,\n",
    "    it tries a minimal repair so you can proceed in a notebook.\n",
    "    \"\"\"\n",
    "    txt = open(path, \"r\", encoding=\"utf-8\").read().strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(txt)\n",
    "    except json.JSONDecodeError:\n",
    "        # Minimal repair: insert commas between }{\n",
    "        repaired = re.sub(r\"}\\s*{\", \"},\\n{\", txt)\n",
    "        # Also ensure list commas between objects: ] not handled; assume list already []\n",
    "        return json.loads(repaired)\n",
    "\n",
    "records = load_json_lenient(JSON_PATH)\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# --- basic derived fields ---\n",
    "df[\"slots_computed\"] = df[\"cores\"] * df[\"machines\"]\n",
    "\n",
    "# normalize to wall-seconds (so speedup differences don’t break comparisons)\n",
    "df[\"mean_response_wall_s\"] = (df[\"mean_response_ms\"] / df[\"speedup\"]) / 1000.0\n",
    "df[\"p95_response_wall_s\"]  = (df[\"p95_response_ms\"]  / df[\"speedup\"]) / 1000.0\n",
    "df[\"mean_wait_wall_s\"]     = (df[\"mean_wait_ms\"]     / df[\"speedup\"]) / 1000.0\n",
    "\n",
    "# --- sanity checks ---\n",
    "bad_slots = df[df[\"slots_computed\"] != df[\"total_slots_at_end\"]][\n",
    "    [\"run_id\",\"dataset\",\"cores\",\"machines\",\"slots_computed\",\"total_slots_at_end\"]\n",
    "]\n",
    "\n",
    "print(\"Rows where cores*machines != total_slots_at_end:\", len(bad_slots))\n",
    "display(bad_slots.head(20))\n",
    "\n",
    "df = df.sort_values([\"dataset\", \"total_slots_at_end\", \"quantum_ms\"]).reset_index(drop=True)\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bad6e7-1321-497b-ba38-a28aac66961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_vs_quantum(df_sub: pd.DataFrame, y: str, title: str, ylog: bool = True):\n",
    "    plt.figure()\n",
    "    for slots, g in df_sub.groupby(\"slots_computed\"):\n",
    "        g = g.sort_values(\"quantum_ms\")\n",
    "        plt.plot(g[\"quantum_ms\"], g[y], marker=\"o\", label=f\"{slots} slots\")\n",
    "\n",
    "    plt.xscale(\"log\")  # quantum = 1,10,20,... works well on log scale\n",
    "    if ylog:\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "    plt.xlabel(\"Quantum (ms, log scale)\")\n",
    "    plt.ylabel(y)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a5db3-ee51-4c49-a177-76c7c46c6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, g in df.groupby(\"dataset\"):\n",
    "    plot_vs_quantum(\n",
    "        g,\n",
    "        y=\"mean_response_ms\",\n",
    "        title=f\"RR: Mean response time vs quantum (sim ms) — dataset={dataset}\",\n",
    "        ylog=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db73bd5-1d65-4c49-91cd-9edf0450fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, g in df.groupby(\"dataset\"):\n",
    "    plot_vs_quantum(\n",
    "        g,\n",
    "        y=\"p95_response_ms\",\n",
    "        title=f\"RR: p95 response time vs quantum (sim ms) — dataset={dataset}\",\n",
    "        ylog=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f45c09-ae48-40e1-8d77-bd86397c8369",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, g in df.groupby(\"dataset\"):\n",
    "    plot_vs_quantum(\n",
    "        g,\n",
    "        y=\"avg_slices_per_job\",\n",
    "        title=f\"RR: Avg slices/job vs quantum — dataset={dataset}\",\n",
    "        ylog=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ad4a2-ee07-4180-8227-241b141607d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, g in df.groupby(\"dataset\"):\n",
    "    plot_vs_quantum(\n",
    "        g,\n",
    "        y=\"mean_response_wall_s\",\n",
    "        title=f\"RR: Mean response vs quantum (wall-normalized seconds) — dataset={dataset}\",\n",
    "        ylog=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20137955-5944-44f1-b74e-08964637af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df[\"avg_slices_per_job\"], df[\"mean_response_ms\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Average slices per job (log)\")\n",
    "plt.ylabel(\"Mean response time (sim ms, log)\")\n",
    "plt.title(\"RR: More slices per job correlates with higher response time\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
